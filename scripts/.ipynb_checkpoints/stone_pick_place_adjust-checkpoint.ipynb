{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "import os\n",
    "import sys\n",
    "import rospy\n",
    "import copy\n",
    "import tf\n",
    "import cv2\n",
    "from cv_bridge import CvBridge, CvBridgeError\n",
    "import numpy as np\n",
    "import moveit_msgs.msg\n",
    "import std_msgs.msg\n",
    "from std_msgs.msg import UInt16, String\n",
    "import geometry_msgs.msg\n",
    "from apriltags_ros.msg import AprilTagDetection, AprilTagDetectionArray\n",
    "from math import pi, cos, sin\n",
    "import math\n",
    "from numpy.linalg import inv\n",
    "import scipy.io\n",
    "from mat4py import loadmat\n",
    "from docx import Document\n",
    "import actionlib\n",
    "from robotiq_2f_gripper_msgs.msg import CommandRobotiqGripperFeedback, CommandRobotiqGripperResult, CommandRobotiqGripperAction, CommandRobotiqGripperGoal\n",
    "from robotiq_2f_gripper_control.robotiq_2f_gripper_driver import Robotiq2FingerGripperDriver as Robotiq\n",
    "from poke_grasp.msg import stone_pose\n",
    "from sensor_msgs.msg import Image, CameraInfo\n",
    "import message_filters\n",
    "\n",
    "from visualization_msgs.msg import Marker\n",
    "from visualization_msgs.msg import MarkerArray\n",
    "from geometry_msgs.msg import Point\n",
    "import moveit_commander\n",
    "\n",
    "import urx\n",
    "import math3d as m3d\n",
    "import logging\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "rospy.init_node('pokegrasp', anonymous=True) #initialize the node\n",
    "scene = moveit_commander.PlanningSceneInterface()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "'''\n",
    "gripper_pub = rospy.Publisher('Robotiq2FGripperRobotOutput', outputMsg.Robotiq2FGripper_robot_output, queue_size=10)\n",
    "servo_pub = rospy.Publisher('servo', UInt16, queue_size=10)\n",
    "line_pub = rospy.Publisher('line_bbox', MarkerArray, queue_size=10)\n",
    "rospy.sleep(1)\n",
    "'''\n",
    "logging.basicConfig(level=logging.WARN)\n",
    "rob = urx.Robot(\"192.168.1.102\")\n",
    "#gripper_pub = rospy.Publisher('Robotiq2FGripperRobotOutput', outputMsg.Robotiq2FGripper_robot_output, queue_size=10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action_name = rospy.get_param('~action_name', 'command_robotiq_action')\n",
    "robotiq_client = actionlib.SimpleActionClient(action_name, CommandRobotiqGripperAction)\n",
    "robotiq_client.wait_for_server()\n",
    "#Robotiq.goto(robotiq_client, pos=0.008+0.006+0.008, speed=0.5, force=10, block=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def multiply(v1, v2):\n",
    "    return v1.x*v2.y - v2.x*v1.y\n",
    "\n",
    "\n",
    "class TwoPoints:\n",
    "    def __init__(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "\n",
    "    def __sub__(self, other):\n",
    "        return TwoPoints(self.x-other.x, self.y-other.y)\n",
    "\n",
    "\n",
    "class Segment:\n",
    "    def __init__(self, point1, point2):\n",
    "        self.point1 = point1\n",
    "        self.point2 = point2\n",
    "\n",
    "    def straddle(self, another_segment):\n",
    "        v1 = another_segment.point1 - self.point1\n",
    "        v2 = another_segment.point2 - self.point1\n",
    "        vm = self.point2 - self.point1\n",
    "        if multiply(v1, vm) * multiply(v2, vm) <= 0:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    def is_cross(self, another_segment):\n",
    "        if self.straddle(another_segment) and another_segment.straddle(self):\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    def cross(self, another_segment, is_plot):\n",
    "        if is_plot == 1:\n",
    "            fig, ax = plt.subplots()\n",
    "            ax.plot([self.point1.x, self.point2.x], [self.point1.y, self.point2.y])\n",
    "            ax.plot([another_segment.point1.x, another_segment.point2.x],\n",
    "                     [another_segment.point1.y, another_segment.point2.y])\n",
    "            ax.invert_xaxis()\n",
    "            plt.show()\n",
    "\n",
    "        if self.is_cross(another_segment):\n",
    "            #print('cross.')\n",
    "            return 1\n",
    "        else:\n",
    "            #print('NOT cross.')\n",
    "            return 0\n",
    "\n",
    "\n",
    "def gactive():\n",
    "    command = outputMsg.Robotiq2FGripper_robot_output();\n",
    "    command.rACT = 1\n",
    "    command.rGTO = 1\n",
    "    command.rSP  = 255\n",
    "    command.rFR  = 150\t\t\t\t\t##force need to be adjusted later\n",
    "    gripper_pub.publish(command)\n",
    "    rospy.sleep(0.5)\n",
    "    return command\n",
    "\n",
    "def greset():\n",
    "    command = outputMsg.Robotiq2FGripper_robot_output();\n",
    "    command.rACT = 0\n",
    "    gripper_pub.publish(command)\n",
    "    rospy.sleep(0.5)\n",
    "\n",
    "def gposition(degree):\n",
    "    command = outputMsg.Robotiq2FGripper_robot_output();\n",
    "    command.rACT = 1\n",
    "    command.rGTO = 1\n",
    "    command.rATR = 0\n",
    "    command.rPR = degree\n",
    "    command.rSP  = 0\n",
    "    command.rFR  = 0 ##force need to be adjusted later\n",
    "    gripper_pub.publish(command)\n",
    "\n",
    "def go_to_home(a, vel):\n",
    "    '''\n",
    "    Hong_joint0 = math.radians(106.83)\n",
    "    Hong_joint1 = math.radians(-77.46)\n",
    "    Hong_joint2 = math.radians(-125.81)\n",
    "    Hong_joint3 = math.radians(-68.64)\n",
    "    Hong_joint4 = math.radians(89.58)\n",
    "    Hong_joint5 = math.radians(-73.07)\n",
    "    '''\n",
    "    \n",
    "    Hong_joint0 = math.radians(123.26)\n",
    "    Hong_joint1 = math.radians(-91.84)\n",
    "    Hong_joint2 = math.radians(-112.92)\n",
    "    Hong_joint3 = math.radians(-67.13)\n",
    "    Hong_joint4 = math.radians(89.86)\n",
    "    Hong_joint5 = math.radians(-56.64)\n",
    "    \n",
    "\n",
    "    rob.movej((Hong_joint0,Hong_joint1, Hong_joint2, Hong_joint3, Hong_joint4, Hong_joint5), a, vel)\n",
    "\n",
    "def add_collision_object(x, y, z, x_l, y_l, z_l, name):\n",
    "    obj_pose = geometry_msgs.msg.PoseStamped()\n",
    "    obj_pose.header.frame_id = \"camera_color_optical_frame\"\n",
    "    obj_pose.pose.position.x = x\n",
    "    obj_pose.pose.position.y = y\n",
    "    obj_pose.pose.position.z = z\n",
    "    obj_pose.pose.orientation.x = 0.0\n",
    "    obj_pose.pose.orientation.y = 0.0\n",
    "    obj_pose.pose.orientation.z = 0.0\n",
    "    obj_pose.pose.orientation.w = 1.0\n",
    "    scene.add_box(name, obj_pose, (x_l,y_l,z_l))\n",
    "\n",
    "def generate_box_rviz(pointA, pointB, pointC, pointD, pointE, pointF, pointG, pointH):\n",
    "    markerArray = MarkerArray()\n",
    "    marker1 = Marker()\n",
    "    marker2 = Marker()\n",
    "    marker1.header.frame_id = \"/camera_color_optical_frame\"\n",
    "    marker1.id = 1\n",
    "    marker1.type = marker1.LINE_STRIP\n",
    "    marker1.action = marker1.ADD\n",
    "    # marker scale\n",
    "    marker1.scale.x = 0.001\n",
    "    marker1.scale.y = 0.001\n",
    "    marker1.scale.z = 0.001\n",
    "\n",
    "    # marker color\n",
    "    marker1.color.a = 1.0\n",
    "    marker1.color.r = 1.0\n",
    "    marker1.color.g = 1.0\n",
    "    marker1.color.b = 0.0\n",
    "\n",
    "    # marker orientaiton\n",
    "    marker1.pose.orientation.x = 0.0\n",
    "    marker1.pose.orientation.y = 0.0\n",
    "    marker1.pose.orientation.z = 0.0\n",
    "    marker1.pose.orientation.w = 1.0\n",
    "\n",
    "    # marker position\n",
    "    marker1.pose.position.x = 0.0\n",
    "    marker1.pose.position.y = 0.0\n",
    "    marker1.pose.position.z = 0.0\n",
    "\n",
    "    # marker line points\n",
    "    marker1.points = []\n",
    "    # first point\n",
    "    first_line_point = Point()\n",
    "    first_line_point.x = pointA[0]\n",
    "    first_line_point.y = pointA[1]\n",
    "    first_line_point.z = pointA[2]\n",
    "    marker1.points.append(first_line_point)\n",
    "    # second point\n",
    "    second_line_point = Point()\n",
    "    second_line_point.x = pointB[0]\n",
    "    second_line_point.y = pointB[1]\n",
    "    second_line_point.z = pointB[2]\n",
    "    marker1.points.append(second_line_point)\n",
    "    # second point\n",
    "    thrid_line_point = Point()\n",
    "    thrid_line_point.x = pointC[0]\n",
    "    thrid_line_point.y = pointC[1]\n",
    "    thrid_line_point.z = pointC[2]\n",
    "    marker1.points.append(thrid_line_point)\n",
    "    # second point\n",
    "    fourth_line_point = Point()\n",
    "    fourth_line_point.x = pointD[0]\n",
    "    fourth_line_point.y = pointD[1]\n",
    "    fourth_line_point.z = pointD[2]\n",
    "    marker1.points.append(fourth_line_point)\n",
    "\n",
    "    markerArray.markers.append(marker1)\n",
    "\n",
    "    # Publish the Marker\n",
    "    line_pub.publish(markerArray)\n",
    "    #line_pub.publish(marker2)\n",
    "\n",
    "def check_obj_front(o1, o2):\n",
    "    check_dist = 0.05\n",
    "    lep1 = TwoPoints(o1[0]+Ra*cos(o1[2]), o1[1]+Ra*sin(o1[2]))\n",
    "    rep1 = TwoPoints(o1[0]-Ra*cos(o1[2]), o1[1]-Ra*sin(o1[2]))\n",
    "    left_bp = TwoPoints(lep1.x, lep1.y-check_dist)\n",
    "    right_bp = TwoPoints(rep1.x, rep1.y-check_dist)\n",
    "    left_line = Segment(lep1, left_bp)\n",
    "    right_line = Segment(rep1, right_bp)\n",
    "\n",
    "    lep2 = TwoPoints(o2[0]+Ra*cos(o2[2]), o2[1]+Ra*sin(o2[2]))\n",
    "    rep2 = TwoPoints(o2[0]-Ra*cos(o2[2]), o2[1]-Ra*sin(o2[2]))\n",
    "    o2_line = Segment(lep2, rep2)\n",
    "\n",
    "    left_cross = left_line.cross(o2_line, 0)\n",
    "    right_cross = right_line.cross(o2_line, 0)\n",
    "    if left_cross == 0 and right_cross == 0:\n",
    "        print(\"Front\")\n",
    "        return 1\n",
    "    else:\n",
    "        print(\"Not Front\")\n",
    "        return 0\n",
    "\n",
    "def plan_psi(num):\n",
    "    theta = []\n",
    "    #(camPt1,camRt1_q) = listener.lookupTransform('/camera_color_optical_frame', '/april_tag_frame_id_1', rospy.Time(0))\n",
    "    #(camPt2,camRt2_q) = listener.lookupTransform('/camera_color_optical_frame', '/april_tag_frame_id_2', rospy.Time(0))\n",
    "    #(camPt3,camRt3_q) = listener.lookupTransform('/camera_color_optical_frame', '/april_tag_frame_id_3', rospy.Time(0))\n",
    "    (camPt5,camRt5_q) = listener.lookupTransform('/camera_color_optical_frame', '/april_tag_frame_id_5', rospy.Time(0))\n",
    "    left_boundary = np.array([[camPt5[0]+0.25, camPt5[0]+0.25], [camPt5[1]+0.12, camPt5[1]-0.12]])\n",
    "    right_boundary = np.array([[camPt5[0], camPt5[0]], [camPt5[1]+0.12, camPt5[1]-0.12]])\n",
    "\n",
    "    (camPt0,camRt0_q) = listener.lookupTransform('/camera_color_optical_frame', '/april_tag_frame_id_'+num, rospy.Time(0))\n",
    "    camRt0_e = tf.transformations.euler_from_quaternion(camRt0_q, axes='sxyz')\n",
    "    #print 'camPt0', math.degrees(camRt0_e[0]),math.degrees(camRt0_e[1]),math.degrees(camRt0_e[2])\n",
    "    if camRt0_e[1] > 0:\n",
    "        obj_rot = pi/2 + camRt0_e[2]\n",
    "    else:\n",
    "        obj_rot = -pi/2 + camRt0_e[2]\n",
    "\n",
    "    search_psi = math.radians(90)\n",
    "    for i in range(60,120,5):\n",
    "        search_psi = math.radians(i)\n",
    "        bbox_rot= obj_rot + search_psi\n",
    "        #print math.degrees(obj_rot), math.degrees(bbox_rot)\n",
    "\n",
    "\n",
    "        bbox_A = np.array([camPt0[0]+d*cos(-obj_rot)+(poke_dist-Rb)*cos(bbox_rot), \\\n",
    "                         camPt0[1]-d*sin(-obj_rot)+(poke_dist-Rb)*sin(bbox_rot)])\n",
    "        bbox_B = np.array([camPt0[0]+d*cos(-obj_rot)-(l_lf+0.08+Rb)*cos(bbox_rot), \\\n",
    "                         camPt0[1]-d*sin(-obj_rot)-(l_lf+0.08+Rb)*sin(bbox_rot)])\n",
    "        bbox_C = np.array([bbox_A[0]-aperture*sin(bbox_rot), bbox_A[1]+(aperture+0.045)*cos(bbox_rot)])\n",
    "        bbox_D = np.array([bbox_B[0]-aperture*sin(bbox_rot), bbox_B[1]+(aperture+0.045)*cos(bbox_rot)])\n",
    "\n",
    "        A = TwoPoints(bbox_A[0], bbox_A[1])\n",
    "        B = TwoPoints(bbox_B[0], bbox_B[1])\n",
    "        C = TwoPoints(bbox_C[0], bbox_C[1])\n",
    "        D = TwoPoints(bbox_D[0], bbox_D[1])\n",
    "        E = TwoPoints(left_boundary[0,0], left_boundary[1,0])\n",
    "        F = TwoPoints(left_boundary[0,1], left_boundary[1,1])\n",
    "        G = TwoPoints(right_boundary[0,0], right_boundary[1,0])\n",
    "        H = TwoPoints(right_boundary[0,1], right_boundary[1,1])\n",
    "\n",
    "        # RVIZ visualization\n",
    "        generate_box_rviz([bbox_A[0],bbox_A[1],camPt0[2]],[bbox_B[0],bbox_B[1],camPt0[2]], \\\n",
    "        [bbox_D[0],bbox_D[1],camPt0[2]], [bbox_C[0],bbox_C[1],camPt0[2]], \\\n",
    "        [left_boundary[0,0], left_boundary[1,0],camPt0[2]], [left_boundary[0,1], left_boundary[1,1],camPt0[2]], \\\n",
    "        [right_boundary[0,0], right_boundary[1,0],camPt0[2]],[right_boundary[0,1], right_boundary[1,1],camPt0[2]] )\n",
    "\n",
    "        add_collision_object(E.x, (E.y+F.y)/2, camPt0[2], 0.005, E.y-F.y, 0.05, 'left_wall')\n",
    "        add_collision_object(G.x, (G.y+H.y)/2, camPt0[2], 0.005, G.y-H.y, 0.05, 'right_wall')\n",
    "\n",
    "        AB = Segment(A, B)\n",
    "        CD = Segment(C, D)\n",
    "        EF = Segment(E, F)\n",
    "        GH = Segment(G, H)\n",
    "        check_lflb = AB.cross(EF,0)\n",
    "        check_lfrb = AB.cross(GH,0)\n",
    "        check_rflb = CD.cross(EF,0)\n",
    "        check_rfrb = CD.cross(GH,0)\n",
    "        if check_lflb == 0 and check_lfrb == 0 and check_rflb == 0 and check_rfrb == 0:\n",
    "            print \"No collision\"\n",
    "            theta.append(search_psi)\n",
    "            return theta\n",
    "        else:\n",
    "            print \"Collision\"\n",
    "\n",
    "def takeSecond(elem):\n",
    "    return elem[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def execute():\n",
    "    global pose_x\n",
    "    global pose_y\n",
    "    global pose_z\n",
    "    global yaw\n",
    "    global pitch\n",
    "    global normal\n",
    "    \n",
    "    ####################### change tcp pose ############################\n",
    "    #rob.set_tcp((0.014/2+0.003, 0.0, 0.32601, 0, 0, 0))\n",
    "    rob.set_tcp((0.01, -0.003, 0.32601, 0, 0, 0))\n",
    "    #rob.set_tcp((0.013/2, 0.0, 0.28118, 0, 0, 0))\n",
    "    #rob.set_tcp((0.024/2, 0, 0.36386, 0, 0, 0))\n",
    "    ####################################################################\n",
    "    rob.translate_tool((0, 0, -0.05-0.045), acc=0.2, vel=0.3)\n",
    "    \n",
    "    camPstone = np.array([pose_x, pose_y, pose_z, 1])\n",
    "    eeTcam = m3d.Transform()\n",
    "    eeTcam.pos = (0.076173, -0.0934057, 0.0074811)\n",
    "    eeTcam_e = tf.transformations.euler_from_quaternion([-0.0143125,0.69183,-0.0012,0.722039], axes='sxyz')\n",
    "    eeTcam.orient.rotate_xb(eeTcam_e[0])\n",
    "    eeTcam.orient.rotate_yb(eeTcam_e[1])\n",
    "    eeTcam.orient.rotate_zb(eeTcam_e[2])\n",
    "    print eeTcam\n",
    "\n",
    "    yaxis = (0, 1, 0)\n",
    "    zaxis = (0, 0, 1)\n",
    "    Ry = tf.transformations.rotation_matrix(pi/2, yaxis)\n",
    "    Rz = tf.transformations.rotation_matrix(-pi/2, zaxis)\n",
    "    eeTtcp = np.matmul(Ry, Rz)\n",
    "    ####################### change tcp pose ############################\n",
    "    #eeTtcp[:3,3] = np.array([0.32601,-0.014/2-0.003,0])\n",
    "    eeTtcp[:3,3] = np.array([0.32601,-0.01,0.003])\n",
    "    #eeTtcp[:3,3] = np.array([0.28118,-0.013/2,0])\n",
    "    #eeTtcp[:3,3] = np.array([0.36386,-0.024/2,0])\n",
    "    ####################################################################\n",
    "    tcpTee = inv(eeTtcp)\n",
    "    print tcpTee\n",
    "    \n",
    "    eeTstone = np.matmul(eeTcam.get_matrix(), camPstone)\n",
    "    print eeTstone\n",
    "    tcpTstone = np.matmul(tcpTee, np.transpose(eeTstone))\n",
    "    print \"tcpTstone\", tcpTstone\n",
    "    \n",
    "    n_normalize = normal / np.linalg.norm(normal)\n",
    "    #if n_normalize[2] > 0:\n",
    "    #    n_normalize[0] = -n_normalize[0]\n",
    "    #    n_normalize[1] = -n_normalize[1]\n",
    "    #    n_normalize[2] = -n_normalize[2]\n",
    "    print \"n_normalize\", n_normalize\n",
    "    n_normalize = np.array([n_normalize[0], n_normalize[1], n_normalize[2], 1])\n",
    "    eeTnormal = np.matmul(eeTcam.get_matrix(), n_normalize)\n",
    "    tcpTnormal = np.matmul(tcpTee, np.transpose(eeTnormal))\n",
    "    print \"tcpTnormal\", tcpTnormal\n",
    "    alpha = math.atan2(tcpTnormal[1], tcpTnormal[0]) # is yaw\n",
    "    if tcpTnormal[0] > 0:\n",
    "        beta = -(pi/2+math.atan2(tcpTnormal[2], tcpTnormal[0])) #tune psi\n",
    "    if tcpTnormal[0] < 0:\n",
    "        beta = -(pi/2+math.atan2(tcpTnormal[2], -tcpTnormal[0])) #tune psi\n",
    "#        beta = -math.atan2(tcpTnormal[2], tcpTnormal[0])-pi/2\n",
    "        #beta = -(pi/2-(math.atan2(tcpTnormal[2], tcpTnormal[0])+pi))\n",
    "    print \"alpha\", alpha*180/pi, \"beta\", beta*180/pi\n",
    "    \n",
    "    move = m3d.Transform((tcpTstone[0,0]+0.01, tcpTstone[1,0]+0.01, 0, 0, 0, 0))\n",
    "    rob.add_pose_tool( move, acc=0.3, vel=0.5, wait=True, command=\"movel\", threshold=None)\n",
    "    #rob.translate_tool((-0.002*cos(beta), 0.006, tcpTstone[2,0]+0.055+0.045), acc=0.1, vel=0.2)\n",
    "    rob.translate_tool((-0.008, 0.005, tcpTstone[2,0]+0.055+0.045+0.0005), acc=0.1, vel=0.2)\n",
    "    \n",
    "    rotation = m3d.Transform((0,0,0,0,beta,alpha))\n",
    "    \n",
    "    rob.add_pose_tool( rotation, acc=0.3, vel=0.5, wait=True, command=\"movel\", threshold=None)\n",
    "    #rotation = m3d.Transform((0,0,0,0,beta,0))\n",
    "    #rob.add_pose_tool( rotation, acc=0.1, vel=0.1, wait=True, command=\"movel\", threshold=None)\n",
    "    \n",
    "    \n",
    "    #rob.translate_tool((0.003*cos(pitch), 0.008, tcpTstone[2,0]+0.2), acc=0.02, vel=0.03)\n",
    "    #rob.translate_tool((0.008*cos(pitch), 0.003, tcpTstone[2,0]+0.2), acc=0.02, vel=0.03)\n",
    "    \n",
    "    \n",
    "    #rotation = m3d.Transform((0,0,0,0,0,alpha))\n",
    "    #rob.add_pose_tool( rotation, acc=0.1, vel=0.1, wait=True, command=\"movel\", threshold=None)\n",
    "    #rotation = m3d.Transform((0,0,0,0,beta,0))\n",
    "    #rob.add_pose_tool( rotation, acc=0.1, vel=0.1, wait=True, command=\"movel\", threshold=None)\n",
    "    \n",
    "    #rotation = m3d.Transform((0,0,0,0,math.radians(45),0))\n",
    "    #rob.add_pose_tool( rotation, acc=0.05, vel=0.05, wait=True, command=\"movel\", threshold=None)\n",
    "\n",
    "    #rotation = m3d.Transform((0,0,0,0,0,yaw))\n",
    "    #rob.add_pose_tool( rotation, acc=0.1, vel=0.1, wait=True, command=\"movel\", threshold=None)\n",
    "    \n",
    "    #rob.translate_tool((0.013, -0.01, 0), acc=0.02, vel=0.03)\n",
    "#    rob.translate_tool((0.006*cos(beta), 0, 0), acc=0.06, vel=0.08)\n",
    "    \n",
    "    ###########################Choose d and psi######################################\n",
    "    rob.translate_tool((0.004+0.0015*int(abs(beta)>10)+0.003*int(abs(beta)>15), 0, 0), acc=0.06, vel=0.08)\n",
    "    psi = math.radians(20)\n",
    "    rotation = m3d.Transform((0,0,0,0,psi,0))\n",
    "    rob.add_pose_tool( rotation, acc=0.3, vel=0.3, wait=True, command=\"movel\", threshold=None)\n",
    "    #################################################################################\n",
    "    \n",
    "    #rob.translate_tool((0, -0.005, 0), acc=0.02, vel=0.03)\n",
    "    \n",
    "    print 0.1226-(tcpTstone[2,0]+0.2)\n",
    "    print \"tcpTstone[2,0]= \",tcpTstone[2,0]\n",
    "    \n",
    "    #rob.translate_tool((0, 0, 0.1196-(tcpTstone[2,0]+0.2+0.002)), acc=0.02, vel=0.03)\n",
    "    #rob.translate_tool((0, 0, 0.015-tcpTstone[2,0]-0.02-0.00-0.045-0.002), acc=0.03, vel=0.05)\n",
    "    ##rob.translate_tool((0, 0, 0.0265), acc=0.03, vel=0.05)\n",
    "\n",
    "    rob.translate_tool((0, 0, 0.0285), acc=0.01, vel=0.05) #2.85 a003 v005\n",
    "    Robotiq.goto(robotiq_client, pos=0.006, speed=0.5, force=10, block=False)\n",
    "    rospy.sleep(.5)\n",
    "    \n",
    "    #rotation = m3d.Transform((0,0,0,0,-pitch,0))\n",
    "    #rob.add_pose_tool( rotation, acc=0.02, vel=0.03, wait=True, command=\"movel\", threshold=None)\n",
    "    \n",
    "    #########################ONLY PICKING################################\n",
    "    # return home\n",
    "    #raw_input()\n",
    " #   rob.translate_tool((0, 0, -0.08), acc=0.02, vel=0.03)\n",
    " #   rob.movel((0, -0.12, 0, 0, 0, 0), acc=0.2, vel=0.2, wait=True, relative=True)\n",
    " #   go_to_home()\n",
    " #   Robotiq.goto(robotiq_client, pos=0.024, speed=0.2, force=10, block=False)\n",
    "    \n",
    "    \n",
    "    ##########################For PLACING################################\n",
    "    rob.translate_tool((0, 0, -0.08), acc=0.3, vel=0.5)\n",
    "    joint = rob.getj()\n",
    "    if joint[5] > pi:\n",
    "        rob.movej((joint[0],joint[1],joint[2],joint[3],joint[4],joint[5]-pi),0.5,0.8)\n",
    "    elif joint[5] < -pi:\n",
    "        rob.movej((joint[0],joint[1],joint[2],joint[3],joint[4],joint[5]+pi),0.5,0.8)\n",
    "    \n",
    "    rob.movel((0, -0.15, 0, 0, 0, 0), acc=0.3, vel=0.5, wait=True, relative=True)\n",
    "    go_to_home(0.5, 0.7)\n",
    "    Robotiq.goto(robotiq_client, pos=0.020, speed=0.5, force=10, block=False)\n",
    "    \n",
    "    '''\n",
    "    rob.movel((-0.35, -0.25, 0, 0, 0, 0), acc=0.2, vel=0.2, wait=True, relative=True)\n",
    "    rotation = m3d.Transform((0,0,0,0,0,-alpha+pi))\n",
    "    rob.add_pose_tool( rotation, acc=0.1, vel=0.1, wait=True, command=\"movel\", threshold=None)\n",
    "    rob.movel((0, 0, -0.173, 0, 0, 0), acc=0.1, vel=0.1, wait=True, relative=True)\n",
    "    #go_to_home()\n",
    "    #Robotiq.goto(robotiq_client, pos=0.008+0.006+0.008, speed=0.2, force=10, block=False)\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<rospy.topics.Subscriber at 0x7ffb405b9250>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def stone_pose_callback(msg):\n",
    "    print(msg)\n",
    "    \n",
    "    global pose_x\n",
    "    global pose_y\n",
    "    global pose_z\n",
    "    global yaw\n",
    "    global pitch\n",
    "    global normal\n",
    "    \n",
    "    pose_x = msg.x\n",
    "    pose_y = msg.y\n",
    "    pose_z = msg.z\n",
    "    yaw = msg.yaw\n",
    "    pitch = msg.pitch\n",
    "    normal = msg.normal\n",
    "    \n",
    "    print 'pose_x = ', pose_x, ',pose_y = ', pose_y, ',pose_z = ', pose_z\n",
    "    \n",
    "    \n",
    "pose_topic = '/stone_pose' #\"/usb_cam/image_raw\"\n",
    "rospy.Subscriber(pose_topic, stone_pose, stone_pose_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "is_send_stone_img = 0\n",
    "stone_img_count = 0\n",
    "\n",
    "pose_x = 0\n",
    "pose_y = 0\n",
    "yaw = 0\n",
    "pitch = 0\n",
    "bridge = CvBridge()\n",
    "\n",
    "def image_callback(color, a_depth):\n",
    "    global is_send_stone_img\n",
    "    global stone_img_count\n",
    "    \n",
    "    #print 'enter img callback', is_send_img\n",
    "    \n",
    "    if is_send_stone_img == 1:\n",
    "        print \"dsag\"\n",
    "        #print(color)\n",
    "        #print(a_depth)\n",
    "        img_count_pub = rospy.Publisher('/stone_img_index', String, queue_size=1)\n",
    "        rospy.sleep(0.5)\n",
    "        cv2_img = bridge.imgmsg_to_cv2(color, \"bgr8\")\n",
    "        cv2.imwrite('../../../../tensorflow_proj/Mask_RCNN/samples/stones/JPEGImages/'+str(stone_img_count)+'.jpeg', cv2_img)\n",
    "        cv2_depth_img = bridge.imgmsg_to_cv2(a_depth, desired_encoding=\"passthrough\")\n",
    "        depth_array = np.array(cv2_depth_img, dtype=np.float32)\n",
    "        print depth_array\n",
    "        #print depth_array[36,532]\n",
    "        cv2.imwrite('../../../../tensorflow_proj/Mask_RCNN/samples/stones/depth/'+str(stone_img_count)+'.jpeg', cv2_depth_img)\n",
    "        np.save('../../../../tensorflow_proj/Mask_RCNN/samples/stones/depth/'+str(stone_img_count)+'.npy', depth_array)\n",
    "        img_count_pub.publish(str(stone_img_count))\n",
    "        print str(stone_img_count)\n",
    "        stone_img_count = stone_img_count + 1\n",
    "        is_send_stone_img = 0\n",
    "        '''\n",
    "        img_count_pub = rospy.Publisher('/stone_img_index', String, queue_size=1)\n",
    "        #cv2_img = bridge.imgmsg_to_cv2(msg, \"bgr8\")\n",
    "        #cv2.imwrite('/home/yuhin/ws_moveit/src/pickpack/Mask_RCNN/log/'+str(carton_img_count)+'.jpeg', cv2_img)\n",
    "        rospy.sleep(1)\n",
    "        #print('from image callback, publish /carton_img_index')\n",
    "        img_count_pub.publish(str(stone_img_count))\n",
    "        print str(stone_img_count)\n",
    "        #stone_img_count = stone_img_count + 1\n",
    "        is_send_stone_img = 0\n",
    "        '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#image_topic = '/camera/color/image_raw' #\"/usb_cam/image_raw\"\n",
    "\n",
    "# Set up your subscriber and define its callback\n",
    "#rospy.Subscriber(image_topic, Image, image_callback)\n",
    "image_color_sub = message_filters.Subscriber('/camera/color/image_raw', Image)\n",
    "image_aligned_depth_sub = message_filters.Subscriber('/camera/aligned_depth_to_color/image_raw', Image)\n",
    "#info_sub = message_filters.Subscriber('/camera/aligned_depth_to_color/camera_info', CameraInfo)\n",
    "\n",
    "ts = message_filters.TimeSynchronizer([image_color_sub, image_aligned_depth_sub], 10)\n",
    "ts.registerCallback(image_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dsag\n",
      "[[206. 206. 206. ... 210. 210. 210.]\n",
      " [206. 206. 206. ... 210. 210. 210.]\n",
      " [206. 206. 206. ... 210. 210. 210.]\n",
      " ...\n",
      " [355. 355. 355. ...   0.   0.   0.]\n",
      " [355. 355. 355. ...   0.   0.   0.]\n",
      " [355. 355. 355. ...   0.   0.   0.]]\n",
      "11\n",
      "header: \n",
      "  seq: 31\n",
      "  stamp: \n",
      "    secs: 0\n",
      "    nsecs:         0\n",
      "  frame_id: ''\n",
      "x: -0.0308783305177\n",
      "y: -0.00792353130144\n",
      "z: 0.172\n",
      "yaw: 2.59073511906\n",
      "pitch: 0.334736837317\n",
      "normal: [0.44197778401748017, -0.049416578712783814, -0.8885443729250995]\n",
      "pose_x =  -0.0308783305177 ,pose_y =  -0.00792353130144 ,pose_z =  0.172\n"
     ]
    }
   ],
   "source": [
    "#stone_img_count = 0\n",
    "\n",
    "try:\n",
    "    Robotiq.goto(robotiq_client, pos=0.022, speed=0.5, force=10, block=False)\n",
    "    go_to_home(0.1, 0.3)\n",
    "    is_send_stone_img = 1\n",
    "    \n",
    "except rospy.ROSInterruptException: pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Transform:\n",
      "<Orientation: \n",
      "array([[ 0.04290745, -0.01806757,  0.99891567],\n",
      "       [-0.02153275,  0.9995875 ,  0.01900464],\n",
      "       [-0.99884698, -0.02232484,  0.04250071]])>\n",
      "<Vector: (0.07617, -0.09341, 0.00748)>\n",
      ">\n",
      "[[ 3.74939946e-33 -1.00000000e+00 -6.12323400e-17 -1.00000000e-02]\n",
      " [ 6.12323400e-17  6.12323400e-17 -1.00000000e+00  3.00000000e-03]\n",
      " [ 1.00000000e+00  0.00000000e+00  6.12323400e-17 -3.26010000e-01]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  1.00000000e+00]]\n",
      "[[ 0.24680474 -0.09739227  0.04581084  1.        ]]\n",
      "tcpTstone [[ 0.08739227]\n",
      " [-0.04281084]\n",
      " [-0.07920526]\n",
      " [ 1.        ]]\n",
      "n_normalize [ 0.44481193 -0.04973346 -0.8942421 ]\n",
      "tcpTnormal [[ 0.15969142]\n",
      " [ 0.47671359]\n",
      " [-1.12312513]\n",
      " [ 1.        ]]\n",
      "alpha 71.4799753162 beta -8.09235168881\n",
      "0.0018052564870829207\n",
      "tcpTstone[2,0]=  -0.07920525648708293\n"
     ]
    }
   ],
   "source": [
    "execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-92.91459280821043"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-2.9145928082104184"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "is_test = 0\n",
    "\n",
    "def cam_cb(tag):\n",
    "    global is_test\n",
    "    if len(tag.detections) >= 0 and is_test == 0:\n",
    "        tag_pos = tag.detections[0].pose.pose.position\n",
    "        tag_q = tag.detections[0].pose.pose.orientation\n",
    "        \n",
    "        camTtag = tf.transformations.quaternion_matrix([tag_q.x, tag_q.y, tag_q.z, tag_q.w])\n",
    "        camTtag[:3,3] = np.array([tag_pos.x, tag_pos.y, tag_pos.z])\n",
    "        print camTtag\n",
    "        \n",
    "        tag_e = tf.transformations.euler_from_quaternion([tag_q.x, tag_q.y, tag_q.z, tag_q.w], axes='sxyz')\n",
    "        camTt0 = m3d.Transform()\n",
    "        camTt0.pos = (tag_pos.x, tag_pos.y, tag_pos.z)\n",
    "        camTt0.orient.rotate_xb(tag_e[0])\n",
    "        camTt0.orient.rotate_yb(tag_e[1])\n",
    "        camTt0.orient.rotate_zb(tag_e[2])\n",
    "        print camTt0\n",
    "        \n",
    "        eeTcam = m3d.Transform()\n",
    "        eeTcam.pos = (0.076173, -0.0934057, 0.0074811)\n",
    "        eeTcam_e = tf.transformations.euler_from_quaternion([-0.0143125,0.69183,-0.0012,0.722039], axes='sxyz')\n",
    "        eeTcam.orient.rotate_xb(eeTcam_e[0])\n",
    "        eeTcam.orient.rotate_yb(eeTcam_e[1])\n",
    "        eeTcam.orient.rotate_zb(eeTcam_e[2])\n",
    "        print eeTcam\n",
    "        \n",
    "        yaxis = (0, 1, 0)\n",
    "        zaxis = (0, 0, 1)\n",
    "        Ry = tf.transformations.rotation_matrix(pi/2, yaxis)\n",
    "        Rz = tf.transformations.rotation_matrix(-pi/2, zaxis)\n",
    "        eeTtcp = np.matmul(Ry, Rz)\n",
    "        tcpTee = inv(eeTtcp)\n",
    "        \n",
    "        #eeTcam = tf.transformations.quaternion_matrix([-0.0143125,0.69183,-0.0012,0.722039])\n",
    "        #eeTcam[:3,3] = np.array([0.076173, -0.0934057, 0.0214811])\n",
    "        #print eeTcam\n",
    "        \n",
    "        #tcpTt0 = np.matmul(tcpTee, eeTcam.get_matrix(), camTt0.get_matrix())\n",
    "        eeTt0 = np.matmul(eeTcam.get_matrix(), camTt0.get_matrix())\n",
    "        tcpTt0 = np.matmul(tcpTee, eeTt0)\n",
    "        \n",
    "        print 'eeTt0', eeTt0\n",
    "        \n",
    "        print 'tcpTt0', tcpTt0\n",
    "        \n",
    "        move = m3d.Transform((tcpTt0[0,3], tcpTt0[1,3], 0, 0, 0, 0))\n",
    "        rob.add_pose_tool( move, acc=0.02, vel=0.03, wait=True, command=\"movel\", threshold=None)\n",
    "        \n",
    "        is_test = 1\n",
    "\n",
    "        \n",
    "go_to_home()\n",
    "#cam_pose_sub = rospy.Subscriber('/tag_detections', AprilTagDetectionArray, cam_cb, queue_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.62280605 -0.77779511 -0.08454225  0.04599101]\n",
      " [-0.7765642  -0.62770655  0.05415281  0.00315694]\n",
      " [-0.09518752  0.03192579 -0.99494728  0.26420449]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "<Transform:\n",
      "<Orientation: \n",
      "array([[ 0.62280605, -0.77779511, -0.08454225],\n",
      "       [-0.7765642 , -0.62770655,  0.05415281],\n",
      "       [-0.09518752,  0.03192579, -0.99494728]])>\n",
      "<Vector: (0.04599, 0.00316, 0.26420)>\n",
      ">\n",
      "<Transform:\n",
      "<Orientation: \n",
      "array([[ 0.04290745, -0.01806757,  0.99891567],\n",
      "       [-0.02153275,  0.9995875 ,  0.01900464],\n",
      "       [-0.99884698, -0.02232484,  0.04250071]])>\n",
      "<Vector: (0.07617, -0.09341, 0.00748)>\n",
      ">\n",
      "eeTt0 [[-0.05433065  0.0098591  -0.99847433  0.34200732]\n",
      " [-0.7914636  -0.61009281  0.03704228 -0.08621926]\n",
      " [-0.6087968   0.79226862  0.04094986 -0.02729848]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "tcpTt0 [[ 0.7914636   0.61009281 -0.03704228  0.08621926]\n",
      " [ 0.6087968  -0.79226862 -0.04094986  0.02729848]\n",
      " [-0.05433065  0.0098591  -0.99847433  0.34200732]\n",
      " [ 0.          0.          0.          1.        ]]\n"
     ]
    }
   ],
   "source": [
    "is_test = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "go_to_home(0.1, 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Robotiq.goto(robotiq_client, pos=0.023, speed=0.01, force=10, block=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "joint = rob.getj()\n",
    "if joint[5] > pi:\n",
    "    rob.movej((joint[0],joint[1],joint[2],joint[3],joint[4],joint[5]-pi),0.5,0.8)\n",
    "elif joint[5] < -pi:\n",
    "    rob.movej((joint[0],joint[1],joint[2],joint[3],joint[4],joint[5]+pi),0.5,0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Transform:\n",
       "<Orientation: \n",
       "array([[ 0.50266238, -0.86395382, -0.03023794],\n",
       "       [-0.86447449, -0.50250343, -0.01319679],\n",
       "       [-0.00379325,  0.03277346, -0.99945561]])>\n",
       "<Vector: (0.52470, -0.00512, 0.00324)>\n",
       ">"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rotation = m3d.Transform((0,0,0,0,0,pi))\n",
    "rob.add_pose_tool( rotation, acc=0.1, vel=0.1, wait=True, command=\"movel\", threshold=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Transform:\n",
       "<Orientation: \n",
       "array([[-0.0130871 ,  0.99982499,  0.01336823],\n",
       "       [ 0.99944032,  0.01349135, -0.03061109],\n",
       "       [-0.03078609,  0.01296013, -0.99944197]])>\n",
       "<Vector: (-0.22448, 0.52547, -0.01750)>\n",
       ">"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rob.set_tcp((0.010, 0.0, 0.32601, 0, 0, 0))\n",
    "rob.get_pose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2*int(2>1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
